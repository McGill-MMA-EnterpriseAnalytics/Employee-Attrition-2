from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
import pandas as pd
import numpy as np
from typing import List, Dict, Any
import logging
from datetime import datetime
import os
import json

# Import the specific functions needed
from .drift_detection import check_drift, check_prediction_drift # Import both functions
from .config import get_settings, PRODUCTION_MODEL_NAME, REPORTS_PATH, DRIFT_REPORT_FILENAME
from .utils import save_json, get_production_model_run_id, download_mlflow_artifact # Import necessary utils

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

app = FastAPI(title="Drift Monitoring API")
settings = get_settings()

# Define consistent artifact paths used by the API - ONLY MLFLOW PATHS
# Feature Drift
REFERENCE_FEATURES_DIR = "reference_data"
REFERENCE_FEATURES_FILENAME = "reference_data.parquet"
MLFLOW_REFERENCE_FEATURES_PATH = f"{REFERENCE_FEATURES_DIR}/{REFERENCE_FEATURES_FILENAME}"

# Prediction Drift
REFERENCE_PREDICTIONS_DIR = "reference_predictions"
REFERENCE_PREDICTIONS_FILENAME = "reference_predictions.csv"
MLFLOW_REFERENCE_PREDICTIONS_PATH = f"{REFERENCE_PREDICTIONS_DIR}/{REFERENCE_PREDICTIONS_FILENAME}"

# Define paths for result files generated by the workflow
LATEST_FEATURE_DRIFT_RESULTS_PATH = os.path.join(REPORTS_PATH, 'feature_drift_results.json')
LATEST_PREDICTION_DRIFT_RESULTS_PATH = os.path.join(REPORTS_PATH, 'prediction_drift_results.json')

# --- Pydantic Models --- 
class FeatureDriftRequest(BaseModel):
    data: List[Dict[str, Any]] # Current feature data

class FeatureDriftResponse(BaseModel):
    dataset_drift: bool
    drift_share: float
    drifted_features: List[str]
    n_drifted_features: int
    timestamp: datetime

class PredictionData(BaseModel):
    # Define expected prediction structure
    prediction: int 
    probability: float
    # Add other optional fields if needed, like EmployeeNumber

class PredictionDriftRequest(BaseModel):
    data: List[PredictionData] # Current prediction data

class PredictionDriftResponse(BaseModel):
    prediction_drift_detected: bool
    prediction_drift_score: float | None # Score might be None
    timestamp: datetime

# --- Helper Function to Get Reference Data Directly from MLflow ---
def get_reference_data_from_mlflow(mlflow_artifact_path: str) -> pd.DataFrame:
    """Get reference data directly from MLflow without saving locally."""
    run_id = get_production_model_run_id(PRODUCTION_MODEL_NAME)
    if not run_id:
        logger.error("Cannot access artifact: Production model run ID not found.")
        raise HTTPException(status_code=503, detail="Reference data not available: No production model run found.")
    
    # Use a temporary directory for the download
    import tempfile
    with tempfile.TemporaryDirectory() as temp_dir:
        downloaded_path = download_mlflow_artifact(run_id, mlflow_artifact_path, temp_dir)
        
        if not downloaded_path or not os.path.exists(downloaded_path):
            logger.error(f"Failed to download artifact: {mlflow_artifact_path}")
            raise HTTPException(status_code=503, detail=f"Reference data not available: Failed to download {mlflow_artifact_path} from run {run_id}.")
        
        # Read the artifact based on file type
        if downloaded_path.endswith('.parquet'):
            data = pd.read_parquet(downloaded_path)
        elif downloaded_path.endswith('.csv'):
            data = pd.read_csv(downloaded_path)
        else:
            logger.error(f"Unsupported file format: {downloaded_path}")
            raise HTTPException(status_code=500, detail=f"Unsupported reference data format: {mlflow_artifact_path}")
        
        logger.info(f"Successfully loaded reference data from MLflow: {mlflow_artifact_path}, shape: {data.shape}")
        return data

# --- API Endpoints --- 
@app.get("/health")
async def health_check():
    """Basic health check endpoint. Checks if the API process is responsive."""
    # Simple check, assumes if endpoint responds, the process is up.
    # Actual data/MLflow checks happen in the drift endpoints.
    # MUST return a simple JSON serializable response.
    return {
        "status": "healthy", 
        "timestamp": datetime.now().isoformat() # Return timestamp as ISO string
    }

@app.post("/drift/feature", response_model=FeatureDriftResponse)
async def check_feature_drift_endpoint(request: FeatureDriftRequest):
    """Check for FEATURE drift."""
    try:
        current_df = pd.DataFrame(request.data)
        logger.info(f"Feature Drift Check: Received data shape: {current_df.shape}")

        # Get reference data directly from MLflow
        reference_df = get_reference_data_from_mlflow(MLFLOW_REFERENCE_FEATURES_PATH)
        logger.info(f"Feature Drift Check: Loaded reference data shape: {reference_df.shape}")
        
        drift_results = check_drift(current_data=current_df, reference_data=reference_df)
        
        if 'error' in drift_results:
            raise HTTPException(status_code=500, detail=f"Error during feature drift calculation: {drift_results['error']}")

        return FeatureDriftResponse(
            dataset_drift=drift_results["dataset_drift"],
            drift_share=drift_results["drift_share"],
            drifted_features=drift_results["drifted_features"],
            n_drifted_features=drift_results["n_drifted_features"],
            timestamp=datetime.now(),
        )
        
    except HTTPException as http_exc:
        raise http_exc
    except Exception as e:
        logger.error(f"Error in /drift/feature endpoint: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

@app.post("/drift/prediction", response_model=PredictionDriftResponse)
async def check_prediction_drift_endpoint(request: PredictionDriftRequest):
    """Check for PREDICTION drift."""
    try:
        # Convert list of Pydantic models to DataFrame
        current_predictions_df = pd.DataFrame([p.dict() for p in request.data])
        logger.info(f"Prediction Drift Check: Received data shape: {current_predictions_df.shape}")
        if current_predictions_df.empty:
             raise HTTPException(status_code=400, detail="Received empty prediction data list.")

        # Get reference predictions directly from MLflow
        reference_predictions_df = get_reference_data_from_mlflow(MLFLOW_REFERENCE_PREDICTIONS_PATH)
        logger.info(f"Prediction Drift Check: Loaded reference predictions shape: {reference_predictions_df.shape}")

        # Call the prediction drift check function
        drift_results = check_prediction_drift(
            current_predictions=current_predictions_df, 
            reference_predictions=reference_predictions_df
        )

        if 'error' in drift_results or drift_results.get('prediction_drift_detected') is None:
            error_msg = drift_results.get('error', 'Unknown error during prediction drift calculation')
            raise HTTPException(status_code=500, detail=error_msg)

        return PredictionDriftResponse(
            prediction_drift_detected=drift_results["prediction_drift_detected"],
            prediction_drift_score=drift_results["prediction_drift_score"],
            timestamp=datetime.now(),
        )

    except HTTPException as http_exc:
        raise http_exc
    except Exception as e:
        logger.error(f"Error in /drift/prediction endpoint: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=f"Internal server error: {str(e)}")

# --- New Endpoints for UI --- 
@app.get("/drift/feature/latest", response_model=FeatureDriftResponse)
async def get_latest_feature_drift():
    """Get the latest feature drift results saved by the workflow."""
    if not os.path.exists(LATEST_FEATURE_DRIFT_RESULTS_PATH):
        raise HTTPException(status_code=404, detail="Latest feature drift results not found.")
    try:
        with open(LATEST_FEATURE_DRIFT_RESULTS_PATH, 'r') as f:
            results = json.load(f)
        # Add a timestamp if it's missing from the stored file (optional)
        if 'timestamp' not in results:
             results['timestamp'] = datetime.fromtimestamp(os.path.getmtime(LATEST_FEATURE_DRIFT_RESULTS_PATH))
        return FeatureDriftResponse(**results)
    except Exception as e:
        logger.error(f"Error reading latest feature drift results: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Could not retrieve latest feature drift results.")

@app.get("/drift/prediction/latest", response_model=PredictionDriftResponse)
async def get_latest_prediction_drift():
    """Get the latest prediction drift results saved by the workflow."""
    if not os.path.exists(LATEST_PREDICTION_DRIFT_RESULTS_PATH):
        raise HTTPException(status_code=404, detail="Latest prediction drift results not found.")
    try:
        with open(LATEST_PREDICTION_DRIFT_RESULTS_PATH, 'r') as f:
            results = json.load(f)
        # Add a timestamp if it's missing from the stored file (optional)
        if 'timestamp' not in results:
             results['timestamp'] = datetime.fromtimestamp(os.path.getmtime(LATEST_PREDICTION_DRIFT_RESULTS_PATH))
        return PredictionDriftResponse(**results)
    except Exception as e:
        logger.error(f"Error reading latest prediction drift results: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Could not retrieve latest prediction drift results.") 