name: Monthly MLOps Pipeline

on:
  # Run at midnight on the first day of every month
  schedule:
    - cron: '0 0 1 * *'
  # Allow manual triggers
  workflow_dispatch:
  # Run on push to main (for testing)
  # push:
  #   branches:
  #     - main
  #   paths:
  #     - 'src/**'
  #     - 'scripts/**'
  #     - '.github/workflows/production_automation.yml'

jobs:
  run_pipeline:
    runs-on: ubuntu-latest
    env: # Set env vars for all steps
        MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
        DATABASE_URL_PYMSSQL: ${{ secrets.DATABASE_URL_PYMSSQL }}
        DATABASE_URL_PYODBC: ${{ secrets.DATABASE_URL_PYODBC }}
        DRIFT_API_URL: ${{ secrets.DRIFT_API_URL }} # Ensure this secret is set in GitHub

    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install poetry
        poetry install --only main # Use --only main for consistency
    
    # Removed Set up environment variables step (using job-level env)
        
    # Step 1: Run batch prediction
    # Assuming batch_predict.py saves predictions and maybe features?
    # Let's assume it saves features to reports/batch_features.json 
    # and predictions to reports/batch_predictions.json
    - name: Run batch prediction
      id: batch_predict
      run: |
        poetry run python scripts/batch_predict.py
        # Add error handling/check if output files exist
        if [ ! -f reports/batch_predictions.json ] || [ ! -f reports/batch_features.json ]; then
          echo "::error::Batch prediction did not produce expected output files."
          exit 1
        fi
        echo "Batch prediction completed."
        
    # Step 2: Check feature drift via API
    - name: Check feature drift
      id: feature_drift
      run: |
        echo "Checking feature drift via API: $DRIFT_API_URL"
        # Prepare data payload (assuming features are in reports/batch_features.json)
        jq -c '{ data: . }' reports/batch_features.json > payload_features.json

        curl -f -X POST "$DRIFT_API_URL/drift/feature" \
          -H "Content-Type: application/json" \
          -d @payload_features.json -o reports/feature_drift_results.json
        
        # Extract result for later steps
        DRIFT_DETECTED=$(jq -r '.dataset_drift' reports/feature_drift_results.json)
        echo "Feature drift detected: $DRIFT_DETECTED"
        echo "drift_detected=$DRIFT_DETECTED" >> $GITHUB_OUTPUT
        
    # Step 3: Check prediction drift via API
    - name: Check prediction drift
      id: prediction_drift
      run: |
        echo "Checking prediction drift via API: $DRIFT_API_URL"
        # Prepare data payload (assuming predictions are in reports/batch_predictions.json)
        jq -c '{ data: . }' reports/batch_predictions.json > payload_predictions.json
        
        curl -f -X POST "$DRIFT_API_URL/drift/prediction" \
          -H "Content-Type: application/json" \
          -d @payload_predictions.json -o reports/prediction_drift_results.json
        
        # Extract result for later steps
        DRIFT_DETECTED=$(jq -r '.prediction_drift_detected' reports/prediction_drift_results.json)
        echo "Prediction drift detected: $DRIFT_DETECTED"
        echo "drift_detected=$DRIFT_DETECTED" >> $GITHUB_OUTPUT

    # Step 4: Retrain if drift detected in EITHER features OR predictions
    - name: Retrain model if drift detected
      # Use the outputs from drift check steps
      if: steps.feature_drift.outputs.drift_detected == 'true' || steps.prediction_drift.outputs.drift_detected == 'true'
      id: retrain
      run: |
        echo "Drift detected in features OR predictions. Starting retraining process..."
        poetry run python scripts/optimize_train_select.py
        
        # Save new reference data after retraining
        echo "Saving new reference data and predictions..."
        poetry run python scripts/save_reference_data.py
        echo "::set-output name=retrained::true"
        
    # Step 5: Create summary issue
    - name: Create summary issue
      # Always run this step to report status
      if: always()
      uses: actions/github-script@v6
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');
          let summary = `## Monthly MLOps Pipeline Summary (${new Date().toISOString().split('T')[0]})\n\n`;
          summary += `- Workflow Status: ${context.job.status}\n`;
          
          // Add feature drift results
          try {
            const featureDrift = JSON.parse(fs.readFileSync('reports/feature_drift_results.json', 'utf8'));
            summary += `\n### Feature Drift Results\n`;
            summary += `- Drift detected: ${featureDrift.dataset_drift}\n`;
            summary += `- Drift share: ${(featureDrift.drift_share * 100).toFixed(2)}%\n`;
            summary += `- Number of drifted features: ${featureDrift.n_drifted_features}\n`;
          } catch (e) { summary += '\n- Could not read feature drift results.\n'; }

          // Add prediction drift results
          try {
            const predDrift = JSON.parse(fs.readFileSync('reports/prediction_drift_results.json', 'utf8'));
            summary += `\n### Prediction Drift Results\n`;
            summary += `- Drift detected: ${predDrift.prediction_drift_detected}\n`;
            summary += `- Drift score: ${predDrift.prediction_drift_score !== null ? predDrift.prediction_drift_score.toFixed(4) : 'N/A'}\n`;
          } catch (e) { summary += '\n- Could not read prediction drift results.\n'; }

          // Add retraining status
          const retrained = '${{ steps.retrain.outputs.retrained }}' === 'true';
          summary += `\n### Retraining Status\n`;
          summary += `- Model Retrained: ${retrained ? 'Yes' : 'No'}\n`;
          
          // Add batch prediction summary if available
          try {
            const predSummary = JSON.parse(fs.readFileSync('reports/batch_prediction_summary.json', 'utf8'));
            summary += `\n### Batch Prediction Results\n`;
            summary += `- Number of predictions: ${predSummary.num_predictions}\n`;
            summary += `- Attrition rate: ${(predSummary.attrition_rate * 100).toFixed(2)}%\n`;
          } catch (e) { summary += '\n- Could not read batch prediction summary.\n'; }
          
          // Add link to workflow run
          summary += `\n[Link to Workflow Run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})\n`;
          
          // Create issue
          await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `Monthly Pipeline ${context.job.status === 'success' ? (retrained ? '✅ Retrained' : '✅ No Drift') : '❌ Failed'} - ${new Date().toISOString().split('T')[0]}`,
            body: summary,
            labels: [`automation-${context.job.status === 'success' ? 'success' : 'failed'}`, retrained ? 'retrained' : 'no-drift']
          }); 