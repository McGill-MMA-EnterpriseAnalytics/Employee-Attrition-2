name: Monthly MLOps Pipeline

on:
  # Run at midnight on the first day of every month
  schedule:
    - cron: '0 0 1 * *'
  # Allow manual triggers
  workflow_dispatch:
  # Run on push to main (for testing)
  push:
    branches:
      - main
    paths:
      - 'src/**'
      - 'scripts/**'
      - '.github/workflows/production_automation.yml'

jobs:
  run_pipeline:
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install poetry
        poetry install
    
    - name: Set up environment variables
      run: |
        echo "MLFLOW_TRACKING_URI=${{ secrets.MLFLOW_TRACKING_URI }}" >> $GITHUB_ENV
        echo "DATABASE_URL_PYMSSQL=${{ secrets.DATABASE_URL_PYMSSQL }}" >> $GITHUB_ENV
        echo "DATABASE_URL_PYODBC=${{ secrets.DATABASE_URL_PYODBC }}" >> $GITHUB_ENV
        echo "DRIFT_API_URL=${{ secrets.DRIFT_API_URL }}" >> $GITHUB_ENV
        
    # Step 1: Run batch prediction
    - name: Run batch prediction
      id: batch_predict
      run: |
        poetry run python scripts/batch_predict.py
        
    # Step 2: Check feature drift
    - name: Check feature drift
      id: feature_drift
      continue-on-error: true
      run: |
        # Get reference data from MLflow
        poetry run python -c "
        import mlflow
        client = mlflow.tracking.MlflowClient()
        model = client.get_latest_versions('EmployeeAttrition', stages=['Production'])[0]
        run = client.get_run(model.run_id)
        reference_data = client.download_artifacts(run.info.run_id, 'reference_data/reference_data.csv')
        "
        
        # Call drift API
        curl -X POST ${{ secrets.DRIFT_API_URL }}/drift/feature \
          -H "Content-Type: application/json" \
          -d @reference_data.json
        
    # Step 3: Check prediction drift
    - name: Check prediction drift
      id: prediction_drift
      continue-on-error: true
      run: |
        # Get reference predictions from MLflow
        poetry run python -c "
        import mlflow
        client = mlflow.tracking.MlflowClient()
        model = client.get_latest_versions('EmployeeAttrition', stages=['Production'])[0]
        run = client.get_run(model.run_id)
        reference_predictions = client.download_artifacts(run.info.run_id, 'reference_predictions/reference_predictions.csv')
        "
        
        # Call drift API
        curl -X POST ${{ secrets.DRIFT_API_URL }}/drift/prediction \
          -H "Content-Type: application/json" \
          -d @reference_predictions.json
        
    # Step 4: Retrain if drift detected
    - name: Retrain model if drift detected
      if: |
        steps.feature_drift.outcome == 'failure' || 
        steps.prediction_drift.outcome == 'failure'
      id: retrain
      run: |
        echo "Drift detected. Starting retraining process..."
        poetry run python scripts/optimize_train_select.py
        
        # Save new reference data after retraining
        poetry run python scripts/save_reference_data.py
        
    # Step 5: Create summary issue
    - name: Create summary issue
      if: always()
      uses: actions/github-script@v6
      with:
        script: |
          const fs = require('fs');
          let summary = '## Monthly MLOps Pipeline Summary\n\n';
          
          // Add feature drift results if available
          if (fs.existsSync('reports/drift_report.json')) {
            const driftReport = JSON.parse(fs.readFileSync('reports/drift_report.json', 'utf8'));
            summary += `### Feature Drift Results\n`;
            summary += `- Drift detected: ${driftReport.dataset_drift}\n`;
            summary += `- Drift share: ${(driftReport.drift_share * 100).toFixed(2)}%\n`;
            summary += `- Number of drifted features: ${driftReport.n_drifted_features}\n\n`;
          }
          
          // Add prediction drift results if available
          if (fs.existsSync('reports/prediction_drift_report.json')) {
            const predDriftReport = JSON.parse(fs.readFileSync('reports/prediction_drift_report.json', 'utf8'));
            summary += `### Prediction Drift Results\n`;
            summary += `- Drift detected: ${predDriftReport.drift_detected}\n`;
            summary += `- Drift score: ${predDriftReport.drift_score}\n`;
            summary += `- Drifted features: ${predDriftReport.drifted_features.join(', ')}\n\n`;
          }
          
          // Add retraining results if available
          if (fs.existsSync('reports/retraining_summary.json')) {
            const retrainSummary = JSON.parse(fs.readFileSync('reports/retraining_summary.json', 'utf8'));
            summary += `### Retraining Results\n`;
            summary += `- Was retrained: ${retrainSummary.was_retrained}\n`;
            summary += `- New model performance: ${retrainSummary.new_model_performance}\n`;
            summary += `- Performance improvement: ${retrainSummary.performance_improvement}\n\n`;
          }
          
          // Add batch prediction results if available
          if (fs.existsSync('reports/batch_prediction_summary.json')) {
            const predSummary = JSON.parse(fs.readFileSync('reports/batch_prediction_summary.json', 'utf8'));
            summary += `### Batch Prediction Results\n`;
            summary += `- Number of predictions: ${predSummary.num_predictions}\n`;
            summary += `- Attrition rate: ${(predSummary.attrition_rate * 100).toFixed(2)}%\n\n`;
          }
          
          // Add error information if available
          if (fs.existsSync('reports/automation_error.json')) {
            const errorSummary = JSON.parse(fs.readFileSync('reports/automation_error.json', 'utf8'));
            summary += `### Error Information\n`;
            summary += `- Error type: ${errorSummary.error_type}\n`;
            summary += `- Error message: ${errorSummary.error}\n\n`;
          }
          
          // Create issue with summary
          await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `Monthly MLOps Pipeline ${context.job.status === 'success' ? '✅' : '❌'} - ${new Date().toISOString().split('T')[0]}`,
            body: summary,
            labels: context.job.status === 'success' ? ['automation-success'] : ['automation-failed']
          }); 