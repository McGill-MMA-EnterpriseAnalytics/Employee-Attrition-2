name: Monthly MLOps Pipeline

permissions:
  contents: read
  packages: write
  issues: write

on:
  # Run at midnight on the first day of every month
  schedule:
    - cron: '0 0 1 * *'
  # Allow manual triggers
  workflow_dispatch:

jobs:
  unit-test:
    if: |
      github.event_name == 'schedule' || 
      github.event_name == 'workflow_dispatch'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install poetry
        poetry install
    
    - name: Set up environment
      run: |
        echo "MLFLOW_TRACKING_URI=http://127.0.0.1:5001" >> $GITHUB_ENV
        echo "DATABASE_URL_PYMSSQL=mssql+pymssql://myuser:Password1!@employeeattrition2.database.windows.net/EmployeeAttrition" >> $GITHUB_ENV
        echo "DATABASE_URL_PYODBC=mssql+pyodbc://myuser:Password1!@employeeattrition2.database.windows.net/EmployeeAttrition?driver=ODBC+Driver+17+for+SQL+Server" >> $GITHUB_ENV
    
    - name: Run tests
      run: |
        poetry run pytest tests/
        
    - name: Run linting
      run: |
        poetry run black . --check
        poetry run isort . --check
        poetry run flake8 .
        poetry run mypy .

  run-pipeline:
    if: |
      github.event_name == 'schedule' || 
      github.event_name == 'workflow_dispatch'

    runs-on: ubuntu-latest

    env: # Set env vars for all steps
      MLFLOW_TRACKING_URI: ${{ secrets.MLFLOW_TRACKING_URI }}
      DATABASE_URL_PYMSSQL: ${{ secrets.DATABASE_URL_PYMSSQL }}
      DATABASE_URL_PYODBC: ${{ secrets.DATABASE_URL_PYODBC }}
      DRIFT_API_URL: ${{ secrets.DRIFT_API_URL }} # Ensure this secret is set in GitHub
      DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}

    outputs:
      feature_drift_detected: ${{ steps.feature_drift.outputs.drift_detected }}
      prediction_drift_detected: ${{ steps.prediction_drift.outputs.drift_detected }}


    steps:
    - uses: actions/checkout@v3
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'
        
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install poetry
        poetry install --only main # Use --only main for consistency
    
    # # Hardcoded env if github secrets are not set
    # - name: Set up environment
    #   run: |
    #     echo "MLFLOW_TRACKING_URI=http://127.0.0.1:5001" >> $GITHUB_ENV
    #     echo "DATABASE_URL_PYMSSQL=mssql+pymssql://myuser:Password1!@employeeattrition2.database.windows.net/EmployeeAttrition" >> $GITHUB_ENV
    #     echo "DATABASE_URL_PYODBC=mssql+pyodbc://myuser:Password1!@employeeattrition2.database.windows.net/EmployeeAttrition?driver=ODBC+Driver+17+for+SQL+Server" >> $GITHUB_ENV
    #     echo "DRIFT_API_URL=http://drift-api:8000" >> $GITHUB_ENV

    - name: Build and run services with Docker Compose
      continue-on-error: true
      run: |
        docker-compose up -d --build
        sleep 15
        docker ps
        if [ $? -ne 0 ]; then
          echo "::error::Docker Compose failed to start."
          echo "status=failed" >> $GITHUB_OUTPUT
        else
          echo "status=success" >> $GITHUB_OUTPUT
        fi

    # Step 1: Run batch prediction
    # Assuming batch_predict.py saves predictions and maybe features?
    # Let's assume it saves features to reports/batch_features.json 
    # and predictions to reports/batch_predictions.json
    - name: Run batch prediction
      id: batch_predict
      run: |
        poetry run python scripts/batch_predict.py
        # Add error handling/check if output files exist
        if [ ! -f reports/batch_predictions.json ] || [ ! -f reports/batch_features.json ]; then
          echo "::error::Batch prediction did not produce expected output files."
          exit 1
        fi
        echo "Batch prediction completed."
        
    # Step 2: Check feature drift via API
    - name: Check feature drift
      id: feature_drift
      run: |
        echo "Checking feature drift via API: $DRIFT_API_URL"
        # Prepare data payload (assuming features are in reports/batch_features.json)
        jq -c '{ data: . }' reports/batch_features.json > payload_features.json

        curl -f -X POST "$DRIFT_API_URL/drift/feature" \
          -H "Content-Type: application/json" \
          -d @payload_features.json -o reports/feature_drift_results.json
        
        # Extract result for later steps
        DRIFT_DETECTED=$(jq -r '.dataset_drift' reports/feature_drift_results.json)
        echo "Feature drift detected: $DRIFT_DETECTED"
        echo "drift_detected=$DRIFT_DETECTED" >> $GITHUB_OUTPUT
        
    # Step 3: Check prediction drift via API
    - name: Check prediction drift
      id: prediction_drift
      run: |
        echo "Checking prediction drift via API: $DRIFT_API_URL"
        # Prepare data payload (assuming predictions are in reports/batch_predictions.json)
        jq -c '{ data: . }' reports/batch_predictions.json > payload_predictions.json
        
        curl -f -X POST "$DRIFT_API_URL/drift/prediction" \
          -H "Content-Type: application/json" \
          -d @payload_predictions.json -o reports/prediction_drift_results.json
        
        # Extract result for later steps
        DRIFT_DETECTED=$(jq -r '.prediction_drift_detected' reports/prediction_drift_results.json)
        echo "Prediction drift detected: $DRIFT_DETECTED"
        echo "drift_detected=$DRIFT_DETECTED" >> $GITHUB_OUTPUT

    # Step 4: Retrain if drift detected in EITHER features OR predictions
    - name: Retrain model if drift detected
      # Use the outputs from drift check steps
      if: steps.feature_drift.outputs.drift_detected == 'true' || steps.prediction_drift.outputs.drift_detected == 'true'
      id: retrain
      run: |
        echo "Drift detected in features OR predictions. Starting retraining process..."
        poetry run python scripts/optimize_train_select.py
        
        # Save new reference data after retraining
        echo "Saving new reference data and predictions..."
        poetry run python scripts/save_reference_data.py
        echo "retrained=true" >> $GITHUB_OUTPUT
        
    # Step 5: Create summary issue
    - name: Create summary issue
      # Always run this step to report status
      if: always()
      uses: actions/github-script@v6
      with:
        github-token: ${{ secrets.GITHUB_TOKEN }}
        script: |
          const fs = require('fs');
          let summary = `## Monthly MLOps Pipeline Summary (${new Date().toISOString().split('T')[0]})\n\n`;
          summary += `- Workflow Status: ${context.job.status}\n`;
          
          // Add feature drift results
          try {
            const featureDrift = JSON.parse(fs.readFileSync('reports/feature_drift_results.json', 'utf8'));
            summary += `\n### Feature Drift Results\n`;
            summary += `- Drift detected: ${featureDrift.dataset_drift}\n`;
            summary += `- Drift share: ${(featureDrift.drift_share * 100).toFixed(2)}%\n`;
            summary += `- Number of drifted features: ${featureDrift.n_drifted_features}\n`;
          } catch (e) { summary += '\n- Could not read feature drift results.\n'; }

          // Add prediction drift results
          try {
            const predDrift = JSON.parse(fs.readFileSync('reports/prediction_drift_results.json', 'utf8'));
            summary += `\n### Prediction Drift Results\n`;
            summary += `- Drift detected: ${predDrift.prediction_drift_detected}\n`;
            summary += `- Drift score: ${predDrift.prediction_drift_score !== null ? predDrift.prediction_drift_score.toFixed(4) : 'N/A'}\n`;
          } catch (e) { summary += '\n- Could not read prediction drift results.\n'; }

          // Add retraining status
          const retrained = '${{ steps.retrain.outputs.retrained }}' === 'true';
          summary += `\n### Retraining Status\n`;
          summary += `- Model Retrained: ${retrained ? 'Yes' : 'No'}\n`;
          
          // Add batch prediction summary if available
          try {
            const predSummary = JSON.parse(fs.readFileSync('reports/batch_prediction_summary.json', 'utf8'));
            summary += `\n### Batch Prediction Results\n`;
            summary += `- Number of predictions: ${predSummary.num_predictions}\n`;
            summary += `- Attrition rate: ${(predSummary.attrition_rate * 100).toFixed(2)}%\n`;
          } catch (e) { summary += '\n- Could not read batch prediction summary.\n'; }
          
          // Add link to workflow run
          summary += `\n[Link to Workflow Run](${context.serverUrl}/${context.repo.owner}/${context.repo.repo}/actions/runs/${context.runId})\n`;
          
          // Create issue
          await github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: `Monthly Pipeline ${context.job.status === 'success' ? (retrained ? '✅ Retrained' : '✅ No Drift') : '❌ Failed'} - ${new Date().toISOString().split('T')[0]}`,
            body: summary,
            labels: [`automation-${context.job.status === 'success' ? 'success' : 'failed'}`, retrained ? 'retrained' : 'no-drift']
          }); 

  # Push docker images to DockerHub (Optional)
  docker-build-push:
    needs: run-pipeline
    if: |
      needs.run-pipeline.outputs.feature_drift_detected == 'true' ||
      needs.run-pipeline.outputs.prediction_drift_detected == 'true'

    runs-on: ubuntu-latest

    env:
      DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
      DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}

    steps:
      - name: Checkout code
        uses: actions/checkout@v3

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to DockerHub
        uses: docker/login-action@v3
        with:
          username: $DOCKER_USERNAME
          password: $DOCKER_PASSWORD

      - name: Build and push mlflow image
        continue-on-error: true
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.mlflow
          push: true
          tags: $DOCKER_USERNAME/employee-attrition-2-mlflow-server:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max
          
      - name: Build and push api image
        continue-on-error: true
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile
          push: true
          tags: $DOCKER_USERNAME/employee-attrition-2-api:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build and push frontend image
        continue-on-error: true
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.frontend
          push: true
          tags: $DOCKER_USERNAME/employee-attrition-2-frontend:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max

      - name: Build and push drift image
        continue-on-error: true
        uses: docker/build-push-action@v5
        with:
          context: .
          file: ./Dockerfile.drift
          push: true
          tags: $DOCKER_USERNAME/employee-attrition-2-drift-api:latest
          cache-from: type=gha
          cache-to: type=gha,mode=max